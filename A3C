import numpy as np

state_size, action_size = 4, 3   # [goal_dist, opponent_dist, x, y]
actor = np.random.rand(state_size, action_size)
critic = np.random.rand(state_size)
lr = 0.01

def softmax(x):
    e = np.exp(x - np.max(x))
    return e / np.sum(e)

for episode in range(300):
    state = np.random.rand(state_size)
    probs = softmax(state @ actor)
    action = np.random.choice(action_size, p=probs)

    reward = 1 if action == 2 else -1   # 2 = score goal
    value = state @ critic
    advantage = reward - value

    actor += lr * advantage * np.outer(state, probs)
    critic += lr * advantage * state

print("Soccer Robot Training Completed!")
